<!--Shree KRISHNAya Namaha-->
<!DOCTYPE html>
<html lang="en">
<head>
    <title>Nagabhushan S N - Project Ideas</title>
    <link rel="stylesheet" href="res/styles/w3.css">
    <link rel="stylesheet" href="res/styles/common.css">
    <link rel="stylesheet" href="res/styles/navigation.css">
    <script src='https://kit.fontawesome.com/a076d05399.js'></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="res/scripts/navigation.js"></script>

    <link rel="stylesheet" href="project_ideas/res/styles/project-ideas.css">
    <!--    <script src="project_ideas/res/scripts/project-ideas.js"></script>-->

    <meta charset="UTF-8">
    <meta name="description" content="Project Ideas Page">
    <meta name="author" content="Nagabhushan S N">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

<!-- Navigation Sidebar - Start-->
<nav class="w3-sidebar w3-collapse w3-light-grey w3-animate-left" style="z-index:3;width:260px" id="nav_panel">
    <div class="w3-container">
        <i onclick="w3_close()" class="w3-hide-large w3-right w3-xlarge w3-padding w3-hover-grey" title="close menu">
            <i class="fas fa-times"></i>
        </i>
        <h4><b>Nagabhushan S N</b></h4>
    </div>
    <div class="w3-bar-block">
        <a href="index.html" class="w3-bar-item w3-button">
            <i class="fa fa-home" style="width: 25px"></i> Home
        </a>
        <a href="research.html" class="w3-bar-item w3-button">
            <i class="fa fa-flask" style="width: 25px"></i> Research
        </a>
        <a href="publications.html" class="w3-bar-item w3-button">
            <i class="fa fa-file-alt" style="width: 25px"></i> Publications
        </a>
        <a href="projects.html" class="w3-bar-item w3-button">
            <i class="fa fa-project-diagram" style="width: 25px"></i> Projects
        </a>
        <a href="work-experience.html" class="w3-bar-item w3-button">
            <i class="fa fa-briefcase" style="width: 25px"></i> Work Experience
        </a>
        <a href="miscellaneous.html" class="w3-bar-item w3-button">
            <i class="fa fa-ellipsis-h" style="width: 25px"></i> Miscellaneous
        </a>
        <a href="project-ideas.html" class="w3-bar-item w3-button selected-page">
            <i class="fas fa-lightbulb" style="width: 25px"></i> Project Ideas
        </a>
        <a href="res/documents/SNB_CV.pdf" target="_blank" class="w3-bar-item w3-button">CV</a>
        <a href="res/documents/SNB_Resume.pdf" target="_blank" class="w3-bar-item w3-button">Resume</a>
    </div>
    <div class="w3-panel w3-large">
        <a href="https://linkedin.com/in/nagabhushan-s-n-52391a68" target="_blank"><i
                class="fab fa-linkedin color-linkedin w3-hover-opacity"></i></a> &ensp;
        <a href="https://github.com/NagabhushanSN95" target="_blank"><i
                class="fab fa-github w3-hover-opacity"></i></a> &ensp;
        <a href="https://stackexchange.com/users/4060371/nagabhushan-s-n?tab=accounts" target="_blank"><img
                class="fa w3-hover-opacity" src="res/images/Icon_StackExchange.svg" alt="Stack Exchange"
                style="width: 25px"/></a> &ensp;
        <a href="https://scholar.google.com/citations?hl=en&user=kFbFZHIAAAAJ" target="_blank"><i
                class="ai ai-google-scholar color-google-scholar w3-hover-opacity"></i></a> &ensp;
        <a href="https://orcid.org/0000-0002-2266-759X" target="_blank"><i
                class="ai ai-orcid color-orcid w3-hover-opacity"></i></a> &ensp;
        <a href="https://publons.com/researcher/3835716/nagabhushan-s-n/" target="_blank"><i
                class="ai ai-publons color-publons w3-hover-opacity"></i></a> &ensp;
    </div>
</nav>

<!-- Overlay effect when opening sidebar on small screens -->
<div class="w3-overlay w3-hide-large w3-animate-opacity" onclick="w3_close()" style="cursor:pointer"
     title="close side menu" id="content_overlay"></div>
<!-- Navigation Sidebar - End-->

<!-- Page content - Start -->
<div class="w3-main" style="margin-left:260px">
    <span class="w3-button w3-hide-large w3-xxlarge w3-hover-text-grey" onclick="w3_open()"><i
            class="fa fa-bars"></i></span>
    <div class="w3-container">
        <h1 class="page-title">Project Ideas</h1>
    </div>

    <div class="w3-container" style="width: 80%; margin-left: 10%; padding-top: 50px">
        <p>
            The below are a list of ideas that I think are interesting. Some of them may be used for academic course
            projects and some may be insufficient. You can build on such ideas. If you have any queries regarding these
            ideas, please don't hesitate to contact me. If you do try these ideas, kindly update me, and I'll update
            your findings here (with due credits, of course). If there is already an existing work on the ideas listed
            below, kindly update me with that as well. I'll add a link to the relevant content.
        </p>
    </div>

    <!-- TODO: Add Contents (Research, Product)    -->

    <div class="w3-container" id="research-ideas" style="width: 80%; margin-left: 10%; padding-top: 30px">
        <a href="project-ideas.html#research-ideas"><h3><u>Research Based Ideas</u></h3></a>

        <div class="w3-container" id="2020-05-03">
            <a href="project-ideas.html#2020-05-03"><h5>2020-05-03: Adversarial training and bias of deep features
                towards local texture</h5></a>
            <p>
                Although deep networks have become extremely powerful for object recognition, they perform poorly in the
                presence of adversarial attacks. In [1], the authors propose a method to train deep networks to be
                robust to adversarial attacks by enforcing BPFC regularization. In [2], the authors show that deep
                networks trained on ImageNet-1k database are biased towards local texture and hence when tested on edge
                maps (where no local texture is present), their efficiency reduces.
            </p>
            <p>
                Since adversarial attacks/examples mainly modify local properties of images, it would be interesting to
                see if training a deep network to be robust to adversarial attacks would lead to lower bias towards
                local texture. One way to verify this would be to test the performance of deep networks, which are
                trained to be robust to adversarial attacks, on edge maps of images from ImageNet-1k database or any
                other similar database.
            </p>

            [1] Sravanti Addepalli <i>et al.</i>
            <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Addepalli_Towards_Achieving_Adversarial_Robustness_by_Enforcing_Feature_Consistency_Across_Bit_CVPR_2020_paper.html"
               target="_blank">"Towards Achieving Adversarial Robustness by Enforcing Feature Consistency Across Bit
                Planes"</a>, CVPR 2020. <br>
            [2] Robert Geirhos <i>et al.</i>
            <a href="https://openreview.net/forum?id=Bygh9j09KX&noteId=HJxSI4x527"
               target="_blank">"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves
                accuracy and robustness"</a>, ICLR 2019.

            <hr class="w3-dark-gray" style="height: 1px; width: 100%">
        </div>

        <div class="w3-container" id="2020-03-25">
            <a href="project-ideas.html#2020-03-25"><h5>2020-03-25: Does ResNet features capture global shape?</h5></a>
            <p>
                In [1], the authors show that deep networks trained on ImageNet-1k database are biased towards local
                texture than global shape. One of the experiments conducted in the paper is to get ResNet-50 [2]
                predictions on edge map of an image. In the paper it is shown that accuracy of ResNet reduces on edge
                maps of images.
            </p>
            <p>
                It would be interesting to see if ResNet features (features tapped before the global pooling operation)
                contain information about global shape. One way to check this is to freeze the weights of previous
                layers of ResNet-50 and train only the last softmax layer on edge maps of images in ImageNet-1k
                database. And then test this new model with edge maps of images.
            </p>

            [1] Robert Geirhos <i>et al.</i>
            <a href="https://openreview.net/forum?id=Bygh9j09KX&noteId=HJxSI4x527"
               target="_blank">"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves
                accuracy and robustness"</a>, ICLR 2019. <br>
            [2] Kaiming He <i>et al.</i>
            <a href="https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html"
               target="_blank">"Deep Residual Learning for Image Recognition"</a>, CVPR 2016.

            <hr class="w3-dark-gray" style="height: 1px; width: 100%">
        </div>

        <div class="w3-container" id="2019-11-19">
            <a href="project-ideas.html#2019-11-19"><h5>2019-11-19: How well can MoCoGAN decompose video into Motion and
                Content?</h5></a>
            <p>
                A video generative model has been proposed in [1], which decomposes video into content and motion.
                Content latent vector remains same across all frames while motion latent vector is generated using a
                recurrent network. A decoder then generates a frame using content and motion latent vectors.
            </p>
            <p>
                It would be interesting to check how good the decomposition is working. To check this, one can change
                the content latent vector mid-generation. Ideally the motion should remain the same while the person
                should change.
            </p>

            [1] Sergey Tulyakov <i>et al.</i>
            <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Tulyakov_MoCoGAN_Decomposing_Motion_CVPR_2018_paper.html"
               target="_blank"> "MoCoGAN: Decomposing Motion and Content for Video Generation"</a>, CVPR 2018.
            <hr class="w3-dark-gray" style="height: 1px; width: 100%">
        </div>

        <div class="w3-container" id="2019-09-23">
            <a href="project-ideas.html#2019-09-23"><h5>2019-09-23: Quantitative Evaluation of GANs</h5></a>
            <p>
                Quantitatively evaluating GAN models has been found challenging. Here, I propose a simple idea to
                evaluate them based on how we would evaluate linear regression. Given a trained GAN model and an image
                from test set, backpropagate the gradients (by keeping the generator weights fixed) to find the input
                which can generate an image close to the test image. The error between the generated image and the test
                image, averaged over all images in the test set, may be evaluated as a quantitative measure for
                evaluating GANs. Various error/similarity measures like MSE, SSIM, VGG MSE or VGG cosine similarity can
                be experimented with.
            </p>
            <!--            <hr class="w3-dark-gray" style="height: 1px; width: 100%">-->
        </div>

    </div>
    <hr class="w3-dark-gray" style="height: 1px; width: 80%; margin-left: 10%">

    <div class="w3-container" id="product-ideas" style="width: 80%; margin-left: 10%; padding-top: 30px">
        <a href="project-ideas.html#product-ideas"><h3><u>Product Based Ideas</u></h3></a>

        <div class="w3-container" id="2018-09-28">
            <a href="project-ideas.html#2018-09-28"><h5>2018-09-28: Image Retrieval using Face Recognition</h5></a>
            <p>
                Build a face detection and recognition system, which can be applied on any new directory of images.
                Build a GUI such that whenever a model encounters an unknown face, it requests the user to enter the
                name of the person. The face recognition model should be able to dynamically learn to classify new
                faces. The model builds an index of the people appearing in the photos and stores it. Later, when a
                query for a particular person is issued, the model should retrieve all the images containing that
                person.
            </p>
            <h6 style="margin-bottom: 0"><b>Update:</b></h6>
            <p style="margin-top: 0">
                This idea has already been implemented in Google Photos. Nonetheless, we may not be willing to upload
                all our private photos to Google Photos. In that case, having an offline model, specifically trained on
                people in our friend circle, may be useful. Although this model may not be able to perform as good as
                Google Photos.
            </p>
            <!--            <hr class="w3-dark-gray" style="height: 1px; width: 100%">-->
        </div>

    </div>
    <hr class="w3-dark-gray" style="height: 1px; width: 80%; margin-left: 10%">
</div>
<!-- Page content - End -->

</body>
</html>
