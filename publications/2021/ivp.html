<!DOCTYPE html>
<html lang="en">
<head>
    <title>Temporal View Synthesis</title>
    <link rel="stylesheet" href="../../res/styles/w3.css">
    <link rel="stylesheet" href="../../res/styles/common.css">
    <link rel="stylesheet" href="../../res/styles/navigation.css">
    <script src='https://kit.fontawesome.com/a076d05399.js'></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <script src="../../res/scripts/navigation.js"></script>

    <link rel="stylesheet" href="ivp/styles/ivp.css">

    <meta charset="UTF-8">
    <meta name="description" content="Revealing Disocclusions in Temporal View Synthesis">
    <meta name="keywords"
          content="Image Synthesis, Video Synthesis, View Synthesis, Temporal View Synthesis, Depth Image Based Rendering, Infilling Vector Prediction, Temporal Guidance, DIBR, TVS, IVP, TGIVP">
    <meta name="author" content="Nagabhushan S N">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

<!-- Page content - Start -->
<div class="w3-main">
    <div class="w3-container" id="title-panel">
        <h1 class="page-title">Revealing Disocclusions in Temporal View Synthesis through Infilling Vector Prediction</h1>
        <p style="text-align: center; font-size: large">
            <a href="https://linkedin.com/in/k-vijayalakshmi-193268208" target="_blank"><u>Vijayalakshmi Kanchana</u></a>,
            <a href="../../index.html" target="_blank"><u>Nagabhushan Somraj</u></a>,
            <a href="https://www.linkedin.com/in/ssyadwad/" target="_blank"><u>Suraj Yadwad</u></a> and
            <a href="https://ece.iisc.ac.in/~rajivs" target="_blank"><u>Rajiv Soundararajan</u></a>
        </p>
        <p style="text-align: center; font-size: large">
            Indian Institute of Science
        </p>
        <div class="w3-container" id="downloads" style="text-align: center">
            <a href="" target="_blank">
                <button class="link-button" title="View paper on WACV">WACV 2022</button>
            </a>
            <a href="https://arxiv.org/abs/2110.08805" target="_blank">
                <button class="link-button" title="View paper on arXiv">arXiv</button>
            </a>
            <a href="" target="_blank">
                <button class="link-button" title="Download Database">Database</button>
            </a>
            <a href="https://github.com/NagabhushanSN95/IVP" target="_blank">
                <button class="link-button" title="View Code on GitHub">Code</button>
            </a>
        </div>
    </div>

    <div class="w3-container" style="width: 90%; margin-left: 5%; margin-top: 50px">
        <div class="w3-container" id="summary">
            <a href="#summary"><h2><u>Temporal view synthesis for frame rate upsampling</u></h2></a>
            Alternate frames are graphically rendered and the intermediate frames are predicted using temporal view synthesis.
            <img src="ivp/images/SummaryFigure.png" alt="Summary Figure" id="fig-summary">
        </div>
        <div class="w3-container" id="video-comparison">
            <a href="#video-comparison"><h2><u>Sample comparison videos with other competing methods</u></h2></a>

            <div class="two-video-row">
                <figure style="width: 60%">
                    <video width="905px" height="315" muted controls>
                        <source src="ivp/videos/Ours_EdgeConnect_Comparison.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <figcaption class="caption">Comparison with EdgeConnect</figcaption>
                </figure>
                <figure style="width: 36%">
                    <video width="477px" height="301px" muted controls>
                        <source src="ivp/videos/Ours_SynSin_Comparison.mp4">
                        Your browser does not support the video tag.
                    </video>
                    <figcaption class="caption">Comparison with SynSin</figcaption>
                </figure>
            </div>

            <div class="one-video-row">
                <figure style="width: 100%">
                    <video width="100%" height="auto" muted controls>
                        <source src="ivp/videos/Ours_EdgeConnect_Comparison.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                    <figcaption class="caption">Blur</figcaption>
                </figure>
                <figure style="width: 100%">
                    <video width="100%" height="auto" muted controls>
                        <source src="ivp/videos/Ours_SynSin_Comparison.mp4">
                        Your browser does not support the video tag.
                    </video>
                    <figcaption class="caption">Shape Distortion</figcaption>
                </figure>
            </div>
        </div>

        <hr class="w3-dark-gray" style="height: 1px; width: 100%">

        <div class="w3-container" id="abstract">
            <a href="#abstract"><h2><u>Abstract</u></h2></a>
            We consider the problem of temporal view synthesis, where the goal is to predict a future video frame from the past frames using knowledge of the depth and relative camera motion.
            In contrast to revealing the disoccluded regions through intensity based infilling, we study the idea of an infilling vector to infill by pointing to a non-disoccluded region in the synthesized view.
            To exploit the structure of disocclusions created by camera motion during their infilling, we rely on two important cues, temporal correlation of infilling directions and depth.
            We design a learning framework to predict the infilling vector by computing a temporal prior that reflects past infilling directions and a normalized depth map as input to the network.
            We conduct extensive experiments on a large scale dataset we build for evaluating temporal view synthesis in addition to the SceneNet RGB-D dataset.
            Our experiments demonstrate that our infilling vector prediction approach achieves superior quantitative and qualitative infilling performance compared to other approaches in literature.
        </div>

        <div class="w3-container" id="ivp-idea">
            <a href="#ivp-idea"><h2><u>Infilling Vectors - Idea</u></h2></a>
            Disocclusions can be infilled by copying intensities from the neighborhood background regions, pointed by the predicted infilling vectors.
            <img src="ivp/images/InfillingVectorIdea.png" alt="Summary Figure" id="fig-ivp-idea">
        </div>

        <hr class="w3-dark-gray" style="height: 1px; width: 100%">

        <div class="w3-container" id="database">
            <a href="#database"><h2><u>IISc VEED Database</u></h2></a>
            <img src="ivp/images/DatabaseSamples.png" alt="Samples from IISc VEED Database" id="fig-veed-samples">
        </div>

        <hr class="w3-dark-gray" style="height: 1px; width: 100%">

        <div class="w3-container" id="comparisons">
            <a href="#comparisons"><h2><u>Qualitative Comparisons</u></h2></a>
            <img src="ivp/images/QualitativeComparisons.png" alt="Qualitative Comparisons" id="fig-qualitative-comparisons">
        </div>

        <hr class="w3-dark-gray" style="height: 1px; width: 100%">

        <div class="w3-container" id="citation">
            <a href="#citation"><h2><u>Citation</u></h2></a>
            If you use our work, please cite our paper:
            <div class="citation" style="margin-bottom: 25px">
                Vijayalakshmi Kanchana, Nagabhushan Somraj, Suraj Yadwad, Rajiv Soundararajan, "Revealing Disocclusions in Temporal View Synthesis through Infilling Vector Prediction", <i>IEEE Winter Conference on Applications of Computer Vision (WACV)</i> 2022.
            </div>

            <u>Bibtex</u>:
            <div class="citation" style="margin-bottom: 25px">
                @article{kanchana2022ivp, <br>
                &ensp; &ensp; title = {Revealing Disocclusions in Temporal View Synthesis through Infilling Vector Prediction}, <br>
                &ensp; &ensp; author = {Kanchana, Vijayalakshmi and Somraj, Nagabhushan and Yadwad, Suraj and Soundararajan, Rajiv}, <br>
                &ensp; &ensp; journal = {IEEE Winter Conference on Applications of Computer Vision (WACV)}, <br>
                &ensp; &ensp; year = {2022} <br>
                }
            </div>
        </div>
    </div>
</div>
<!-- Page content - End -->

</body>
</html>
